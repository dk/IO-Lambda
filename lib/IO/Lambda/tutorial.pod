=head1 NAME

A gentle introduction to asynchronous programming

=head1 Preface

Every program communicates with the world by inhaling and exhaling data in one
or another way, and programs written in Perl are no exception. This article is
about using Perl for managing input and output, or I/O. Despite the simple
name, input and output is much more than reading and writing. Opening and
closing connections and files, reporting errors, memory mapping, various
portability issues, these and other topics always accompany data transfer, in
which applications, and therefore users, are mostly interested in. 

Perl, as a high-level language, takes pride in making simple reading
and writing as much simple as possible. Consider the cryptic, but highly
expressive construct

    print while <>;

which is, if expanded in full, is identical to

    while (1) {
        $_ = readline;
        if ( not defined $_) {
            # exit loop on EOF
            last;
        }
        print $_;
    }

which is although more readable, but may cause still questions. For example,
where does C<readline> reads from, and how much exactly? Or, where does C<print>
send data, and why doesn't it check whether it has succeeded or not?

It is a blessing of Perl, that the programmer not only doesn't ask these
questions, but is often unaware of them when those higher-level constructs.  It
is also somewhat a curse, that when such questions are asked, and needed to be
answered, that can only be done after underlying concepts of file input and
output are explained. This however requires that higher-level Perl constructs
should be dissected and analyzed, so their powers and weaknesses could be
understood more clear, rather than being viewed as unreadable black magic.

This article tries to follow a similar pattern as it aims to explain modern
uses of I/O. The article starts from very basic and low-lever concepts, working
through problems faced by these, explaining evolution of various metologies,
their strong and weak points, and arrives to higher-level constructs that
incorporate previous solution in an elegant manner. It is my strong belief that
elegant concepts lead to elegant code, which is always a pleasure to work with.
Quote Tao of Programming, 'A well-written program is its own heaven; a
poorly-written program is its own hell.'. This, often unspoken rule, inspires
many programmers to write highest quality code, even though there may be no one
to appreciate it. Also with this rule in mind, I'd like to present my view on
domain of input and output, its problems, and ways to solve them.

=head1 Introduction to input/output

=head2 Files and handles

Perl I/O system is built mostly around I<libc> runtime library. All
input/output notions are therefore inherited from C, and such terms as
I<handle>, I<buffered I/O>, I<socket> etc are identical to the terms used in
broader contexts, and are not dependent on the language. Standard input and
output, sockets, file handles, these entites are provided and managed by
I<libc>. Perl inherits basic functionality of these objects, often extends it,
sometimes uses system-dependent additional functionality to enhance it,
providing a portable interface to these objects, often more portable than
the interface of I<libc> itself is.

Perl was originally developed under Unix. One of the promintent Unix ideology
features is the famous statement "everything as a file". What ths means, is
that access to devices, hard disks, controllers, network sockets, pipes, disk
files, a large majority of possible ways for a process to interact with the
world, boils down to a small set of common operations, most often reading and
writing, that can be applied to files of various types. This phrase also might
cause confusion, because nowadays the word "file" is usually attributed to disk
files, whereas in this context it means a kernel resource, that a program can
access by obtaining a handle to it, read from and write to, and perform other
resource-specific operations.

There are several standard ways to interact with files, too provided by
I<libc>. There are different groups of operations. Some are inherent to all
types of files, such as opening and closing. Others only make sense on sockets,
for example sending and receiving datagrams. There are also operations that
execute resource-specific commands, for example ejecting a CD-ROM on modern
Unix systems can be done through a C<ioctl> call.

Consider the simplest "Hello world" program:

    perl -le 'print q(Hello world!)'

The program sends information to the standard output, a special resource each
program is guaranteed to have after it has started. Standard output, along with
standard input and standard error, is usually, but not necessarily, is
connected with the controlling terminal. It takes a shell redirection to send
the output to a file, while the program itself doesn't mark the difference:
    
    perl -le 'print q(Hello world!)' > out.txt

It is only possible to write to the standard output, and read from standard
input. However, many types of files can usually be opened for both operations. 

File handles, as provided by C<libs>, are unique positive integers.  Even
though this fact is rarely exploited in Perl, because of the power of the I/O
handles associated to scalars and globs such as STDIN, Perl provides function
C<fileno> that provides the file handle number for a given scalar or glob.  By
default, STDIN is tied to file handle 0, STDOUT to 1, and STDERR to 2.  The
following program closes the STDOUT handle, however continues to print to the standard
output under another name:

    # Issue dup() call on file handle #1
    # dup() creates another file handle that refers to 
    # the stream that is associated with the oroginal handle
    # See "man dup" for details.
    open NEW_STDOUT, ">&=", 1;

    close STDOUT;
    print NEW_STDOUT "hello, world!\n";

To summarize, the underlying concepts of a file are not unique to Perl, nor to
C, nor to any other language, but are an essential part of POSIX standard.
Therefore, when further down declarations such "Windows does not provide
non-blocking pipes" should not be understood as if this is Perl's limitation.
Perl documentation often refers to the system documentation, often where
portability issues are important.

=head2 Buffered and unbuffered I/O

There are several architectural layers where buffering may affect input and
output. If a program is being run from a command prompt, and is getting input
from the terminal, its input is normally line-buffered, which means that input
is available to the program only after a newline character is entered.
The following code
 
    print while <STDIN>;

reads whatever input is provided to the standard input, and prints it back to
the standard output, line by line. However, if it is desired to print every
character or keystroke as soon as these are entered, without waiting for the
newline, such program won't work. The terminal must be first switched to the
so-called "raw" mode. Perl provides no API for the raw input, however,
additional modules L<Term::ReadKey> deals with it quite effectively.
The following program switches the terminal into the raw mode, and prints
keystrokes as soon as the user presses them:




(Note: windows command prompt does not work that way. However, libraries
know how to work with windows prompt, using native windows API).

Input can also be buffered on I<libc> level. There are three modes


While input buffering is traditionally associated with terminals, output
buffering is implemented by I<libc>. which has different but related APIs for
buffered and unbuffered file handles (I<fopen> and I<open>, I<fread> and
I<read> functions, etc). The buffered output is so often preferred, that
it made into a default. However certain areas require non-buffered output.
For example, CGI programs often want to send output as soon as it is 
available. To do so, they turn off buffering by

  $| = 1

where C<$|> is, quote C<perldoc perlvar>, "If set to nonzero, forces a flush
right away and after every write or print on the currently selected output
channel.". Alternatively, buffering can be managed using standard L<IO::Handle>
module:

   use IO::Handle;
   $io = new IO::Handle;

   # issue libc's fdopen() to asscociate $io with STDOUT
   $io-> fdopen(fileno(STDOUT),"w");

   # now printing to STDOUT is buffered, while printing to
   # $io is not 
   $io-> autoflush(0);

   # 'b' appears before 'a'
   print STDOUT "a";
   print $io "b";

This example is to demonstrate that using buffered and non-buffered
output on the same resource can lead to strange effects, so it usually
should be avoided.

Perl functions, that are used mostly for basic input-output, deal with buffered
I/O, however can be told not to buffer, or to change the buffer size.  These
are C<open>, C<close>, C<read>, C<readline>, C<seek>, C<tell>, C<print>
(instead of C<write>, which in Perl is not opposite to C<read>, but does
formatted output, see "perldoc -f write"). There is also a set of lesser-known
functions, that deal exclusively with non-buffered I/O, as close to I<libc> as
possible. Those are: C<sysopen>, C<sysread>, C<syswrite>, C<sysseek>,
C<sysclose>.  It is mostly these functions that are used when implementing
socket and pipe interactions. It's not impossible to use the buffered
functions, by explicitly turning the buffering off, however it is usually not
done, because these function provide greater control over data transmission,
which is useful for such, often asynchronous, interactions.

=head2 Synchronous and asynchronous I/O

POSIX declares two semantics for files, blocking and non-blocking.  The
semantics mainly differs by how does system behaves when a program isses one of
I<read>, I<write>, etc calls, when they cannot read or write the requested
amount of bytes right away. Under such condition, operating files in the blocking
mode stops execution of the caller program, until the requested data is
transferred, or error is occured. The non-blocking mode never stops the execution,
and copies as much data as possible either from or to kernel I/O buffers.

Not only reading and writing calls can behave differently. TCP connect, for 
example, can be done in two ways. I<connect()> call in the blocking mode
does not return until the connection is through. In the non-blocking mode,
if connection couldn't be established immediately (for example on a local
interface), I<connect()> returns a special error value, EINPROGRESS on unix,
or EWOULDBLOCK on Windows. Later, the socket can be checked by other calls
to see whether the connection succeeded or not.

Consider difference in complexity of programming using these two 
semantics. I deliberately show here low-level socket programming without
help from any higher-level module. The code is shown for demonstration
of the concept rather than for any real use.

First, a TCP socket needed to be prepared

    use strict;
    use Socket;
    use IO::Handle;

    my $socket = IO::Handle-> new;
    socket( $socket, PF_INET, SOCK_STREAM, getprotobyname('tcp'))
        or die "socket() error:$!";

and remote address and port to be chosen:

    my $addr = inet_aton('www.google.com')
        or die "cannot resolve www.google.com";
    my $name = sockaddr_in( 80, $addr);

Now, the codepaths differ. The blocking version of the program
needs only one call:

    connect( $socket, $name) or die "connect() error:$!"
    print "connection established\n";

However, the non-blocking version is more complex. The socket
needs to be told that the non-blocking semantics is desired.
This is done by issuing a C<fcntl()> call:

    use Fcntl qw(F_GETFL F_SETFL O_NONBLOCK);

    # query existing socket flags
    my $flags = fcntl( $socket, F_GETFL, 0);
    die "fcntl() error:$!" unless defined $flags;

    # add non-blocking flag
    fcntl( $socket, F_SETFL, $flags | O_NONBLOCK)
       or die "fcntl() error:$!";

The situation is already exacerbated by the fact that on Windows,
not only sockets are by default non-blocking, but also module
C<Fcntl> doesn't export the F_GETFL constants. Thus, this part
has to be wrapped in a condition similar to the following:
   
    if ( $^O ne 'MSWin32') {
    }

Next, the I<connect()> is issued, but it also has to be checked for
errors:

    use Errno qw(EWOULDBLOCK EINPROGRESS); 
    my $ok = connect( $socket, $name);
    $ok = 1 if not($ok) && ($! == EWOULDBLOCK || $! == EINPROGRESS);
    die "Connect error: $!" unless $ok;

which means that EWOULDBLOCK and EINPROGRESS are not really errors.

Now, while the connection is underway, the program has to use one of the
standard facility, function C<select()> that accepts zero or more files, and a
timeout value. The function blocks (no matter whether used on blocking or
non-blocking files) until either the timeout expires, or system signals that
data arrived, or can be written to, to at least one of the files.

C<select()> accepts file handles in a form of bit vectors, formatted so that 
each bit, if is set, corresponds to the file handle number. It also accepts
three such vectors, one for handles awaiting when they can be read from,
one for those awaiting when they can be written to, and one for special
out-of-band messages. They are called correspondingly read, write, and
exception vectors:

    my $write = '';
    # TCP connect will be marked as writable when 
    # either is succeeds, or error occurs
    vec( $write, fileno( $socket ), 1) = 1;

    # wait for 10 seconds
    my $n_files = select( undef, $write, undef, 10);
    die "select() error:$!" if $n_files < 0;
    die "timeout occured" if $n_files == 0;

C<select()> returns number of files ready, or 0 for timeout, or -1 for
an error. C<select()> is a fragile call, if at least one of the files
passed to it is invalid, then the error will be thrown. Moreover,
depending on the system, the error can be a legitimate error, not
to be reacted upon. For example errors EAGAIN or EINTR tell that the
call was interrupted by a signal, and system didn't restart the
the call, so we have to do that by ourselves:
    
    use Errno qw(EINTR EAGAIN);

    # wait for 10 seconds
    my $time    = time;
    my $timeout = 10;
 RESTART:
    my $n_files = select( undef, $write, undef, $timeout);
    if ( $n_files < 0) {
	 # use Time::HiRes qw(time) is recommended
         die "select() error:$!" unless $! == EINTR or $! == EAGAIN;
         $timeout = time - $time;
         goto RESTART;
    }

The signals themselves also add confusion. By default, C<$SIG{PIPE}> aborts the
program on I/O error. We need to protect against such condition too, before any
I/O takes place:

    $SIG{PIPE} = undef;

Now, back to the program. Even if C<select()> returns a positive
number of files, that doesn't mean that thej connection succeeded.
To check for that, the socket must be queried directly:

    my $error = unpack('i', getsockopt( $socket, SOL_SOCKET, SO_ERROR));
    if ($error) {
          # This trick uses duality of error scalar $! and its
          # counterpart $^E on Windows. These scalars report (and assign)
          # error numbers as integers, but in string context return
          # system-specific error description.
          if ( $^O eq 'MSWin32') {
              $^E = $error;
              die "connect() error: $^E";
          } else {
              $! = $error;
              die "connect() error: $!";
          }
    }

Finally, after jumping from all the hoops, the socket is connected.  Of course
it is impractical to write programs in such low-level, explicit style. Wrapper
libraries, which are discussed below, are best for these purposes.

=head2 Reading and writing


=head1 Wrapper modules: simple abstractions

=head1 HYPE

IO::Lambda finally became a framework, where both I/O and lambda calculus are
represented in equal parts. Contrary to the majority of I/O frameworks,
implemented in declarative languages, IO::Lambda is much more than a callback
and event wrapper. The module relies heavily on concepts borrowed from
functional languages, and brings back the simplicity of the declarative
programming style, that is only available when one employs threads, coroutines,
or co-processes.

=head1 AUTHOR

Dmitry Karasik, E<lt>dmitry@karasik.eu.orgE<gt>.

=cut
